{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ca7cd4",
   "metadata": {},
   "source": [
    "### ETAPA 1: Preparação dos Dados para Recomendação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e2e24a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import train_test_split as surprise_train_test_split\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddfbabf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "CSV = os.getenv(\"CSV_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bddc3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo de previsões 'C:/Users/pedro/Documents/Estudos/FIAP/Challenges/ClickBus/Desafios/data/csv/previsoes_finais_desafio2.csv' carregado com sucesso.\n",
      "\n",
      "Temos 50225 clientes com probabilidade de compra >= 83%.\n",
      "A base de clientes com alta probabilidade é maior que 50k.\n",
      "Mantendo os Top 50k clientes com maior probabilidade.\n",
      "\n",
      "O DataFrame de vendas foi filtrado.\n",
      "Número original de vendas: 1133310\n",
      "Número de vendas após o filtro: 337135\n"
     ]
    }
   ],
   "source": [
    "caminho_vendas = f'{CSV}vendas.csv'\n",
    "df_vendas = pd.read_csv(caminho_vendas, sep=',', encoding='utf-8')\n",
    "\n",
    "# 1. Carregar as previsões do Desafio 2\n",
    "# (Ajuste o nome do arquivo e o caminho se necessário)\n",
    "try:\n",
    "    caminho_previsoes = f'{CSV}previsoes_finais_desafio2.csv'\n",
    "    df_previsoes = pd.read_csv(caminho_previsoes)\n",
    "    print(f\"Arquivo de previsões '{caminho_previsoes}' carregado com sucesso.\")\n",
    "\n",
    "    # 2. Definir o limite de probabilidade\n",
    "    PROB_LIMITE = 83 # 85%\n",
    "\n",
    "    # 3. Filtrar os clientes com alta probabilidade de compra\n",
    "    clientes_alta_prob = df_previsoes[df_previsoes['probabilidade_recompra_30d'] >= PROB_LIMITE]\n",
    "    \n",
    "    # 4. Verificar a quantidade de clientes selecionados\n",
    "    print(f\"\\nTemos {len(clientes_alta_prob)} clientes com probabilidade de compra >= {PROB_LIMITE}%.\")\n",
    "\n",
    "    # Se tivermos mais de 50k clientes, podemos manter apenas os top 50k\n",
    "    if len(clientes_alta_prob) > 50000:\n",
    "        print(\"A base de clientes com alta probabilidade é maior que 50k.\")\n",
    "        print(\"Mantendo os Top 50k clientes com maior probabilidade.\")\n",
    "        clientes_alta_prob = clientes_alta_prob.nlargest(50000, 'probabilidade_recompra_30d')\n",
    "\n",
    "    # 5. Filtrar o DataFrame de vendas para manter apenas as transações desses clientes\n",
    "    lista_clientes_selecionados = clientes_alta_prob['fk_contact'].unique()\n",
    "    df_vendas_filtrado = df_vendas[df_vendas['fk_contact'].isin(lista_clientes_selecionados)].copy()\n",
    "\n",
    "    print(f\"\\nO DataFrame de vendas foi filtrado.\")\n",
    "    print(f\"Número original de vendas: {len(df_vendas)}\")\n",
    "    print(f\"Número de vendas após o filtro: {len(df_vendas_filtrado)}\")\n",
    "    \n",
    "    # Substituir o df_vendas original pelo filtrado para o restante do notebook\n",
    "    df_vendas = df_vendas_filtrado\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: O arquivo de previsões 'previsoes_desafio2.csv' não foi encontrado.\")\n",
    "    print(\"O notebook continuará a execução com todos os clientes, mas o ideal é aplicar o filtro.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8337c43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas 'hora_da_compra' e 'dia_da_semana' criadas com sucesso.\n",
      "\n",
      "DataFrame para o sistema de recomendação criado com sucesso.\n",
      "Temos 287135 exemplos de treino (apenas de clientes de alta probabilidade).\n"
     ]
    }
   ],
   "source": [
    "# ETAPA 1: Preparação dos Dados para Recomendação\n",
    "\n",
    "# Garante que a coluna de data de compra está no formato correto\n",
    "df_vendas['date_purchase'] = pd.to_datetime(df_vendas['date_purchase'])\n",
    "\n",
    "# Cria a coluna 'hora_da_compra' a partir de 'time_purchase'\n",
    "df_vendas['hora_da_compra'] = pd.to_datetime(df_vendas['time_purchase'], format='%H:%M:%S').dt.hour\n",
    "\n",
    "# Cria a coluna 'dia_da_semana' a partir de 'date_purchase'\n",
    "dias_semana_map = {\n",
    "    'Monday': '2-Segunda', 'Tuesday': '3-Terça', 'Wednesday': '4-Quarta',\n",
    "    'Thursday': '5-Quinta', 'Friday': '6-Sexta', 'Saturday': '7-Sábado', 'Sunday': '1-Domingo'\n",
    "}\n",
    "df_vendas['dia_da_semana'] = df_vendas['date_purchase'].dt.day_name().map(dias_semana_map)\n",
    "\n",
    "print(\"Colunas 'hora_da_compra' e 'dia_da_semana' criadas com sucesso.\")\n",
    "# Removido o .head() para um output mais limpo\n",
    "\n",
    "# 1. Criar a feature 'rota'\n",
    "df_vendas['rota'] = df_vendas['place_origin_departure'] + ' -> ' + df_vendas['place_destination_departure']\n",
    "\n",
    "# 2. Ordenar as transações por cliente e data\n",
    "df_vendas['datetime'] = pd.to_datetime(df_vendas['date_purchase'].astype(str) + ' ' + df_vendas['time_purchase'])\n",
    "df_vendas = df_vendas.sort_values(by=['fk_contact', 'datetime'])\n",
    "\n",
    "# 3. CRIAR A VARIÁVEL-ALVO (y)\n",
    "df_vendas['proxima_rota'] = df_vendas.groupby('fk_contact')['rota'].shift(-1)\n",
    "\n",
    "# 4. Criar o DataFrame de treino\n",
    "df_recomendacao = df_vendas.dropna(subset=['proxima_rota']).copy()\n",
    "\n",
    "print(\"\\nDataFrame para o sistema de recomendação criado com sucesso.\")\n",
    "print(f\"Temos {len(df_recomendacao)} exemplos de treino (apenas de clientes de alta probabilidade).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7597c033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de treino: 229708 interações\n",
      "Dados de teste: 57427 interações\n",
      "\n",
      "--- Performance do Modelo de Baseline ---\n",
      "O modelo de 'rota mais frequente' acertou a próxima compra em 41.75% das vezes.\n"
     ]
    }
   ],
   "source": [
    "# 1. DIVIDIR OS DADOS EM TREINO E TESTE\n",
    "train_data, test_data = train_test_split(df_recomendacao, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Dados de treino: {len(train_data)} interações\")\n",
    "print(f\"Dados de teste: {len(test_data)} interações\")\n",
    "\n",
    "# 2. CONSTRUIR O MODELO DE BASELINE\n",
    "most_frequent_routes = train_data.groupby('fk_contact')['rota'].agg(lambda x: x.value_counts().index[0])\n",
    "baseline_model = most_frequent_routes.to_dict()\n",
    "\n",
    "# 3. AVALIAR O BASELINE NO CONJUNTO DE TESTE\n",
    "test_data['recomendacao_baseline'] = test_data['fk_contact'].map(baseline_model)\n",
    "acertos = test_data[test_data['proxima_rota'] == test_data['recomendacao_baseline']].shape[0]\n",
    "total_testes = len(test_data)\n",
    "acuracia_baseline = (acertos / total_testes) * 100\n",
    "\n",
    "print(f\"\\n--- Performance do Modelo de Baseline ---\")\n",
    "print(f\"O modelo de 'rota mais frequente' acertou a próxima compra em {acuracia_baseline:.2f}% das vezes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8406716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o treinamento do modelo de Cadeias de Markov...\n",
      "Modelo treinado com sucesso.\n",
      "\n",
      "Gerando recomendações para o conjunto de teste...\n",
      "Recomendações geradas.\n",
      "\n",
      "--- Performance Final dos Modelos ---\n",
      "Acurácia do Baseline (Rota Mais Frequente): 41.75%\n",
      "Acurácia do SVD: 17.39%\n",
      "Acurácia do Cadeias de Markov: 37.21%\n",
      "\n",
      "AVALIAIAÇÃO: O modelo de Cadeias de Markov não superou o baseline.\n"
     ]
    }
   ],
   "source": [
    "# ETAPA 6: Modelo Sequencial (Cadeias de Markov)\n",
    "\n",
    "print(\"Iniciando o treinamento do modelo de Cadeias de Markov...\")\n",
    "\n",
    "# 1. Construir a Matriz de Transição\n",
    "# Para cada rota 'origem', contamos a frequência de cada 'próxima_rota'\n",
    "# Isso nos dará a probabilidade de transição P(Próxima Rota | Rota Atual)\n",
    "transition_counts = train_data.groupby('rota')['proxima_rota'].value_counts()\n",
    "transition_totals = train_data.groupby('rota')['proxima_rota'].count()\n",
    "transition_probabilities = transition_counts.div(transition_totals, level='rota')\n",
    "\n",
    "# 2. Criar o modelo (um dicionário com a transição mais provável)\n",
    "# Para cada rota, pegamos a 'próxima_rota' com a maior probabilidade\n",
    "markov_model = {}\n",
    "# Usamos .loc para pegar o primeiro índice (a rota mais provável) para cada grupo\n",
    "idx = transition_probabilities.groupby('rota').idxmax()\n",
    "# Extraímos os valores de 'proxima_rota'\n",
    "most_likely_transitions = idx.apply(lambda x: x[1])\n",
    "markov_model = most_likely_transitions.to_dict()\n",
    "\n",
    "print(\"Modelo treinado com sucesso.\")\n",
    "\n",
    "# 3. Gerar recomendações para o conjunto de teste\n",
    "print(\"\\nGerando recomendações para o conjunto de teste...\")\n",
    "\n",
    "# A recomendação é simplesmente a transição mais provável a partir da rota atual do cliente\n",
    "# Usamos .get() para o caso de uma rota no teste não ter sido vista no treino\n",
    "test_data['recomendacao_markov'] = test_data['rota'].map(markov_model)\n",
    "print(\"Recomendações geradas.\")\n",
    "\n",
    "# 4. Avaliar a acurácia do modelo\n",
    "test_data_markov_eval = test_data.dropna(subset=['recomendacao_markov'])\n",
    "acertos_markov = test_data_markov_eval[test_data_markov_eval['proxima_rota'] == test_data_markov_eval['recomendacao_markov']].shape[0]\n",
    "total_testes_markov = len(test_data_markov_eval)\n",
    "acuracia_markov = (acertos_markov / total_testes_markov) * 100\n",
    "\n",
    "print(f\"\\n--- Performance Final dos Modelos ---\")\n",
    "print(f\"Acurácia do Baseline (Rota Mais Frequente): {acuracia_baseline:.2f}%\")\n",
    "print(f\"Acurácia do SVD: 17.39%\")\n",
    "print(f\"Acurácia do Cadeias de Markov: {acuracia_markov:.2f}%\")\n",
    "\n",
    "if acuracia_markov > acuracia_baseline:\n",
    "    print(\"\\nAVALIAÇÃO: SUCESSO! O modelo de Cadeias de Markov é superior ao baseline.\")\n",
    "else:\n",
    "    print(\"\\nAVALIAIAÇÃO: O modelo de Cadeias de Markov não superou o baseline.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1c78142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a criação do modelo híbrido...\n",
      "Recomendações do modelo híbrido geradas com sucesso.\n",
      "\n",
      "--- Performance Final dos Modelos ---\n",
      "Acurácia do Baseline (Rota Mais Frequente): 41.75%\n",
      "Acurácia do SVD: 17.39%\n",
      "Acurácia do Cadeias de Markov: 37.21%\n",
      "Acurácia do Modelo Híbrido: 37.01%\n",
      "\n",
      "AVALIAÇÃO: O modelo Híbrido não superou o baseline. O comportamento de lealdade à rota ainda é a melhor estratégia.\n"
     ]
    }
   ],
   "source": [
    "# ETAPA 7: Modelo Híbrido (Markov com Fallback para o Baseline)\n",
    "\n",
    "print(\"Iniciando a criação do modelo híbrido...\")\n",
    "\n",
    "# 1. Gerar recomendações com o modelo de Markov\n",
    "# (Já fizemos isso na etapa anterior, a coluna 'recomendacao_markov' já existe)\n",
    "\n",
    "# 2. Preencher os valores nulos da recomendação de Markov com a recomendação do Baseline\n",
    "# Usamos o .fillna() para aplicar a lógica de fallback\n",
    "test_data['recomendacao_hibrida'] = test_data['recomendacao_markov'].fillna(test_data['recomendacao_baseline'])\n",
    "\n",
    "print(\"Recomendações do modelo híbrido geradas com sucesso.\")\n",
    "\n",
    "# 3. Avaliar a acurácia do modelo Híbrido\n",
    "# Removemos os casos onde nem o Markov nem o Baseline conseguiram gerar uma recomendação\n",
    "test_data_hibrido_eval = test_data.dropna(subset=['recomendacao_hibrida'])\n",
    "\n",
    "acertos_hibrido = test_data_hibrido_eval[test_data_hibrido_eval['proxima_rota'] == test_data_hibrido_eval['recomendacao_hibrida']].shape[0]\n",
    "total_testes_hibrido = len(test_data_hibrido_eval)\n",
    "acuracia_hibrido = (acertos_hibrido / total_testes_hibrido) * 100\n",
    "\n",
    "print(f\"\\n--- Performance Final dos Modelos ---\")\n",
    "print(f\"Acurácia do Baseline (Rota Mais Frequente): {acuracia_baseline:.2f}%\")\n",
    "print(f\"Acurácia do SVD: 17.39%\")\n",
    "print(f\"Acurácia do Cadeias de Markov: {acuracia_markov:.2f}%\")\n",
    "print(f\"Acurácia do Modelo Híbrido: {acuracia_hibrido:.2f}%\")\n",
    "\n",
    "if acuracia_hibrido > acuracia_baseline:\n",
    "    print(\"\\nAVALIAÇÃO: SUCESSO! O modelo Híbrido superou o baseline e é o nosso melhor modelo!\")\n",
    "else:\n",
    "    print(\"\\nAVALIAÇÃO: O modelo Híbrido não superou o baseline. O comportamento de lealdade à rota ainda é a melhor estratégia.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654f2009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados divididos por tempo.\n",
      "Data de corte: 2024-03-17\n",
      "Período de Treino: 2021-01-01 a 2024-03-17\n",
      "Período de Teste: 2024-03-17 a 2024-04-01\n",
      "Dados de treino: 282768 interações\n",
      "Dados de teste: 4367 interações\n"
     ]
    }
   ],
   "source": [
    "# --- MUDANÇA NA ETAPA 2: Divisão Temporal ---\n",
    "\n",
    "# Encontra a data mais recente no nosso dataframe de recomendação\n",
    "data_mais_recente = df_recomendacao['datetime'].max()\n",
    "# Define a data de corte (ex: 30 dias antes da data mais recente)\n",
    "data_corte = data_mais_recente - pd.Timedelta(days=60)\n",
    "\n",
    "# O conjunto de treino são todos os dados ANTES da data de corte\n",
    "train_data = df_recomendacao[df_recomendacao['datetime'] < data_corte]\n",
    "# O conjunto de teste são todos os dados DEPOIS da data de corte\n",
    "test_data = df_recomendacao[df_recomendacao['datetime'] >= data_corte].copy()\n",
    "\n",
    "print(f\"Dados divididos por tempo.\")\n",
    "print(f\"Data de corte: {data_corte.date()}\")\n",
    "print(f\"Período de Treino: {train_data['datetime'].min().date()} a {train_data['datetime'].max().date()}\")\n",
    "print(f\"Período de Teste: {test_data['datetime'].min().date()} a {test_data['datetime'].max().date()}\")\n",
    "print(f\"Dados de treino: {len(train_data)} interações\")\n",
    "print(f\"Dados de teste: {len(test_data)} interações\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be10cfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a avaliação final do modelo Baseline...\n",
      "\n",
      "--- Performance do Modelo (Métricas Validadas) ---\n",
      "Acurácia@1 (Acertar a 1ª recomendação): 41.75%\n",
      "Recall@5 (Acertar entre as 5 primeiras): 49.21%\n",
      "\n",
      "\n",
      "--- Simulação de Impacto no Negócio (Backtesting Temporal) ---\n",
      "Clientes únicos no período de teste: 3105\n",
      "\n",
      "Resultado Simulado do Grupo de Teste (Com Modelo):\n",
      "O modelo acertou a recomendação para 1572 clientes únicos.\n",
      "Taxa de Conversão Estimada com o Modelo: 50.63%\n",
      "\n",
      "--- Conclusão da Prova de Valor ---\n",
      "O backtesting mostra que o modelo teria gerado um UPLIFT de 50.63% na taxa de conversão.\n",
      "Se aplicado aos 50.000 clientes-alvo, isso se traduziria em aproximadamente 25314 vendas a mais no período.\n"
     ]
    }
   ],
   "source": [
    "# ETAPA 3: Avaliação Final e Prova de Valor com Backtesting\n",
    "\n",
    "print(\"Iniciando a avaliação final do modelo Baseline...\")\n",
    "\n",
    "# --- Parte 1: Cálculo do Recall@5 ---\n",
    "# (Esta parte cria a coluna 'recomendacao_baseline_top5' que estava causando o erro)\n",
    "\n",
    "top_5_frequent_routes = train_data.groupby('fk_contact')['rota'].apply(lambda x: x.value_counts().head(5).index.tolist())\n",
    "baseline_model_top5 = top_5_frequent_routes.to_dict()\n",
    "\n",
    "test_data.loc[:, 'recomendacao_baseline_top5'] = test_data['fk_contact'].map(baseline_model_top5)\n",
    "test_data.loc[:, 'recomendacao_baseline_top5'] = test_data['recomendacao_baseline_top5'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "def check_hit(row):\n",
    "    return row['proxima_rota'] in row['recomendacao_baseline_top5']\n",
    "\n",
    "hits = test_data.apply(check_hit, axis=1).sum()\n",
    "total_testes = len(test_data)\n",
    "recall_at_5 = (hits / total_testes) * 100\n",
    "\n",
    "print(f\"\\n--- Performance do Modelo (Métricas Validadas) ---\")\n",
    "print(f\"Acurácia@1 (Acertar a 1ª recomendação): {acuracia_baseline:.2f}%\")\n",
    "print(f\"Recall@5 (Acertar entre as 5 primeiras): {recall_at_5:.2f}%\")\n",
    "\n",
    "# --- Parte 2: Simulação de Uplift de Conversão (Prova de Valor Corrigida) ---\n",
    "# (Esta parte agora usa a coluna que garantimos ter sido criada na parte 1)\n",
    "\n",
    "acertos_df = test_data[test_data.apply(lambda row: row['proxima_rota'] in row['recomendacao_baseline_top5'], axis=1)]\n",
    "clientes_convertidos_pelo_modelo = acertos_df['fk_contact'].nunique()\n",
    "clientes_unicos_no_teste = test_data['fk_contact'].nunique()\n",
    "taxa_conversao_modelo = (clientes_convertidos_pelo_modelo / clientes_unicos_no_teste) * 100\n",
    "uplift_percentual = taxa_conversao_modelo - 0.0\n",
    "vendas_adicionais_estimadas = (50000 * (uplift_percentual / 100))\n",
    "\n",
    "print(f\"\\n\\n--- Simulação de Impacto no Negócio (Backtesting Temporal) ---\")\n",
    "print(f\"Clientes únicos no período de teste: {clientes_unicos_no_teste}\")\n",
    "print(f\"\\nResultado Simulado do Grupo de Teste (Com Modelo):\")\n",
    "print(f\"O modelo acertou a recomendação para {clientes_convertidos_pelo_modelo} clientes únicos.\")\n",
    "print(f\"Taxa de Conversão Estimada com o Modelo: {taxa_conversao_modelo:.2f}%\")\n",
    "\n",
    "print(f\"\\n--- Conclusão da Prova de Valor ---\")\n",
    "print(f\"O backtesting mostra que o modelo teria gerado um UPLIFT de {uplift_percentual:.2f}% na taxa de conversão.\")\n",
    "print(f\"Se aplicado aos 50.000 clientes-alvo, isso se traduziria em aproximadamente {int(vendas_adicionais_estimadas)} vendas a mais no período.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
