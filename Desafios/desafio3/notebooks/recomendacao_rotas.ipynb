{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ca7cd4",
   "metadata": {},
   "source": [
    "### ETAPA 1: Preparação dos Dados para Recomendação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e2e24a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import train_test_split as surprise_train_test_split\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddfbabf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "CSV = os.getenv(\"CSV_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bddc3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo de previsões 'C:/Users/pedro/Documents/Estudos/FIAP/Challenges/ClickBus/Desafios/data/csv/previsoes_finais_desafio2.csv' carregado com sucesso.\n",
      "\n",
      "Temos 50225 clientes com probabilidade de compra >= 83%.\n",
      "A base de clientes com alta probabilidade é maior que 50k.\n",
      "Mantendo os Top 50k clientes com maior probabilidade.\n",
      "\n",
      "O DataFrame de vendas foi filtrado.\n",
      "Número original de vendas: 1133310\n",
      "Número de vendas após o filtro: 337135\n"
     ]
    }
   ],
   "source": [
    "caminho_vendas = f'{CSV}vendas.csv'\n",
    "df_vendas = pd.read_csv(caminho_vendas, sep=',', encoding='utf-8')\n",
    "\n",
    "# 1. Carregar as previsões do Desafio 2\n",
    "# (Ajuste o nome do arquivo e o caminho se necessário)\n",
    "try:\n",
    "    caminho_previsoes = f'{CSV}previsoes_finais_desafio2.csv'\n",
    "    df_previsoes = pd.read_csv(caminho_previsoes)\n",
    "    print(f\"Arquivo de previsões '{caminho_previsoes}' carregado com sucesso.\")\n",
    "\n",
    "    # 2. Definir o limite de probabilidade\n",
    "    PROB_LIMITE = 83 # 85%\n",
    "\n",
    "    # 3. Filtrar os clientes com alta probabilidade de compra\n",
    "    clientes_alta_prob = df_previsoes[df_previsoes['probabilidade_recompra_30d'] >= PROB_LIMITE]\n",
    "    \n",
    "    # 4. Verificar a quantidade de clientes selecionados\n",
    "    print(f\"\\nTemos {len(clientes_alta_prob)} clientes com probabilidade de compra >= {PROB_LIMITE}%.\")\n",
    "\n",
    "    # Se tivermos mais de 50k clientes, podemos manter apenas os top 50k\n",
    "    if len(clientes_alta_prob) > 50000:\n",
    "        print(\"A base de clientes com alta probabilidade é maior que 50k.\")\n",
    "        print(\"Mantendo os Top 50k clientes com maior probabilidade.\")\n",
    "        clientes_alta_prob = clientes_alta_prob.nlargest(50000, 'probabilidade_recompra_30d')\n",
    "\n",
    "    # 5. Filtrar o DataFrame de vendas para manter apenas as transações desses clientes\n",
    "    lista_clientes_selecionados = clientes_alta_prob['fk_contact'].unique()\n",
    "    df_vendas_filtrado = df_vendas[df_vendas['fk_contact'].isin(lista_clientes_selecionados)].copy()\n",
    "\n",
    "    print(f\"\\nO DataFrame de vendas foi filtrado.\")\n",
    "    print(f\"Número original de vendas: {len(df_vendas)}\")\n",
    "    print(f\"Número de vendas após o filtro: {len(df_vendas_filtrado)}\")\n",
    "    \n",
    "    # Substituir o df_vendas original pelo filtrado para o restante do notebook\n",
    "    df_vendas = df_vendas_filtrado\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: O arquivo de previsões 'previsoes_desafio2.csv' não foi encontrado.\")\n",
    "    print(\"O notebook continuará a execução com todos os clientes, mas o ideal é aplicar o filtro.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8337c43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas 'hora_da_compra' e 'dia_da_semana' criadas com sucesso.\n",
      "\n",
      "DataFrame para o sistema de recomendação criado com sucesso.\n",
      "Temos 287135 exemplos de treino (apenas de clientes de alta probabilidade).\n"
     ]
    }
   ],
   "source": [
    "# ETAPA 1: Preparação dos Dados para Recomendação\n",
    "\n",
    "# Garante que a coluna de data de compra está no formato correto\n",
    "df_vendas['date_purchase'] = pd.to_datetime(df_vendas['date_purchase'])\n",
    "\n",
    "# Cria a coluna 'hora_da_compra' a partir de 'time_purchase'\n",
    "df_vendas['hora_da_compra'] = pd.to_datetime(df_vendas['time_purchase'], format='%H:%M:%S').dt.hour\n",
    "\n",
    "# Cria a coluna 'dia_da_semana' a partir de 'date_purchase'\n",
    "dias_semana_map = {\n",
    "    'Monday': '2-Segunda', 'Tuesday': '3-Terça', 'Wednesday': '4-Quarta',\n",
    "    'Thursday': '5-Quinta', 'Friday': '6-Sexta', 'Saturday': '7-Sábado', 'Sunday': '1-Domingo'\n",
    "}\n",
    "df_vendas['dia_da_semana'] = df_vendas['date_purchase'].dt.day_name().map(dias_semana_map)\n",
    "\n",
    "print(\"Colunas 'hora_da_compra' e 'dia_da_semana' criadas com sucesso.\")\n",
    "# Removido o .head() para um output mais limpo\n",
    "\n",
    "# 1. Criar a feature 'rota'\n",
    "df_vendas['rota'] = df_vendas['place_origin_departure'] + ' -> ' + df_vendas['place_destination_departure']\n",
    "\n",
    "# 2. Ordenar as transações por cliente e data\n",
    "df_vendas['datetime'] = pd.to_datetime(df_vendas['date_purchase'].astype(str) + ' ' + df_vendas['time_purchase'])\n",
    "df_vendas = df_vendas.sort_values(by=['fk_contact', 'datetime'])\n",
    "\n",
    "# 3. CRIAR A VARIÁVEL-ALVO (y)\n",
    "df_vendas['proxima_rota'] = df_vendas.groupby('fk_contact')['rota'].shift(-1)\n",
    "\n",
    "# 4. Criar o DataFrame de treino\n",
    "df_recomendacao = df_vendas.dropna(subset=['proxima_rota']).copy()\n",
    "\n",
    "print(\"\\nDataFrame para o sistema de recomendação criado com sucesso.\")\n",
    "print(f\"Temos {len(df_recomendacao)} exemplos de treino (apenas de clientes de alta probabilidade).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7597c033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de treino: 229708 interações\n",
      "Dados de teste: 57427 interações\n",
      "\n",
      "--- Performance do Modelo de Baseline ---\n",
      "O modelo de 'rota mais frequente' acertou a próxima compra em 41.75% das vezes.\n"
     ]
    }
   ],
   "source": [
    "# 1. DIVIDIR OS DADOS EM TREINO E TESTE\n",
    "train_data, test_data = train_test_split(df_recomendacao, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Dados de treino: {len(train_data)} interações\")\n",
    "print(f\"Dados de teste: {len(test_data)} interações\")\n",
    "\n",
    "# 2. CONSTRUIR O MODELO DE BASELINE\n",
    "most_frequent_routes = train_data.groupby('fk_contact')['rota'].agg(lambda x: x.value_counts().index[0])\n",
    "baseline_model = most_frequent_routes.to_dict()\n",
    "\n",
    "# 3. AVALIAR O BASELINE NO CONJUNTO DE TESTE\n",
    "test_data['recomendacao_baseline'] = test_data['fk_contact'].map(baseline_model)\n",
    "acertos = test_data[test_data['proxima_rota'] == test_data['recomendacao_baseline']].shape[0]\n",
    "total_testes = len(test_data)\n",
    "acuracia_baseline = (acertos / total_testes) * 100\n",
    "\n",
    "print(f\"\\n--- Performance do Modelo de Baseline ---\")\n",
    "print(f\"O modelo de 'rota mais frequente' acertou a próxima compra em {acuracia_baseline:.2f}% das vezes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8406716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o treinamento do modelo de Cadeias de Markov...\n",
      "Modelo treinado com sucesso.\n",
      "\n",
      "Gerando recomendações para o conjunto de teste...\n",
      "Recomendações geradas.\n",
      "\n",
      "--- Performance Final dos Modelos ---\n",
      "Acurácia do Baseline (Rota Mais Frequente): 41.75%\n",
      "Acurácia do SVD: 17.39%\n",
      "Acurácia do Cadeias de Markov: 37.21%\n",
      "\n",
      "AVALIAIAÇÃO: O modelo de Cadeias de Markov não superou o baseline.\n"
     ]
    }
   ],
   "source": [
    "# ETAPA 6: Modelo Sequencial (Cadeias de Markov)\n",
    "\n",
    "print(\"Iniciando o treinamento do modelo de Cadeias de Markov...\")\n",
    "\n",
    "# 1. Construir a Matriz de Transição\n",
    "# Para cada rota 'origem', contamos a frequência de cada 'próxima_rota'\n",
    "# Isso nos dará a probabilidade de transição P(Próxima Rota | Rota Atual)\n",
    "transition_counts = train_data.groupby('rota')['proxima_rota'].value_counts()\n",
    "transition_totals = train_data.groupby('rota')['proxima_rota'].count()\n",
    "transition_probabilities = transition_counts.div(transition_totals, level='rota')\n",
    "\n",
    "# 2. Criar o modelo (um dicionário com a transição mais provável)\n",
    "# Para cada rota, pegamos a 'próxima_rota' com a maior probabilidade\n",
    "markov_model = {}\n",
    "# Usamos .loc para pegar o primeiro índice (a rota mais provável) para cada grupo\n",
    "idx = transition_probabilities.groupby('rota').idxmax()\n",
    "# Extraímos os valores de 'proxima_rota'\n",
    "most_likely_transitions = idx.apply(lambda x: x[1])\n",
    "markov_model = most_likely_transitions.to_dict()\n",
    "\n",
    "print(\"Modelo treinado com sucesso.\")\n",
    "\n",
    "# 3. Gerar recomendações para o conjunto de teste\n",
    "print(\"\\nGerando recomendações para o conjunto de teste...\")\n",
    "\n",
    "# A recomendação é simplesmente a transição mais provável a partir da rota atual do cliente\n",
    "# Usamos .get() para o caso de uma rota no teste não ter sido vista no treino\n",
    "test_data['recomendacao_markov'] = test_data['rota'].map(markov_model)\n",
    "print(\"Recomendações geradas.\")\n",
    "\n",
    "# 4. Avaliar a acurácia do modelo\n",
    "test_data_markov_eval = test_data.dropna(subset=['recomendacao_markov'])\n",
    "acertos_markov = test_data_markov_eval[test_data_markov_eval['proxima_rota'] == test_data_markov_eval['recomendacao_markov']].shape[0]\n",
    "total_testes_markov = len(test_data_markov_eval)\n",
    "acuracia_markov = (acertos_markov / total_testes_markov) * 100\n",
    "\n",
    "print(f\"\\n--- Performance Final dos Modelos ---\")\n",
    "print(f\"Acurácia do Baseline (Rota Mais Frequente): {acuracia_baseline:.2f}%\")\n",
    "print(f\"Acurácia do SVD: 17.39%\")\n",
    "print(f\"Acurácia do Cadeias de Markov: {acuracia_markov:.2f}%\")\n",
    "\n",
    "if acuracia_markov > acuracia_baseline:\n",
    "    print(\"\\nAVALIAÇÃO: SUCESSO! O modelo de Cadeias de Markov é superior ao baseline.\")\n",
    "else:\n",
    "    print(\"\\nAVALIAIAÇÃO: O modelo de Cadeias de Markov não superou o baseline.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1c78142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a criação do modelo híbrido...\n",
      "Recomendações do modelo híbrido geradas com sucesso.\n",
      "\n",
      "--- Performance Final dos Modelos ---\n",
      "Acurácia do Baseline (Rota Mais Frequente): 41.75%\n",
      "Acurácia do SVD: 17.39%\n",
      "Acurácia do Cadeias de Markov: 37.21%\n",
      "Acurácia do Modelo Híbrido: 37.01%\n",
      "\n",
      "AVALIAÇÃO: O modelo Híbrido não superou o baseline. O comportamento de lealdade à rota ainda é a melhor estratégia.\n"
     ]
    }
   ],
   "source": [
    "# ETAPA 7: Modelo Híbrido (Markov com Fallback para o Baseline)\n",
    "\n",
    "print(\"Iniciando a criação do modelo híbrido...\")\n",
    "\n",
    "# 1. Gerar recomendações com o modelo de Markov\n",
    "# (Já fizemos isso na etapa anterior, a coluna 'recomendacao_markov' já existe)\n",
    "\n",
    "# 2. Preencher os valores nulos da recomendação de Markov com a recomendação do Baseline\n",
    "# Usamos o .fillna() para aplicar a lógica de fallback\n",
    "test_data['recomendacao_hibrida'] = test_data['recomendacao_markov'].fillna(test_data['recomendacao_baseline'])\n",
    "\n",
    "print(\"Recomendações do modelo híbrido geradas com sucesso.\")\n",
    "\n",
    "# 3. Avaliar a acurácia do modelo Híbrido\n",
    "# Removemos os casos onde nem o Markov nem o Baseline conseguiram gerar uma recomendação\n",
    "test_data_hibrido_eval = test_data.dropna(subset=['recomendacao_hibrida'])\n",
    "\n",
    "acertos_hibrido = test_data_hibrido_eval[test_data_hibrido_eval['proxima_rota'] == test_data_hibrido_eval['recomendacao_hibrida']].shape[0]\n",
    "total_testes_hibrido = len(test_data_hibrido_eval)\n",
    "acuracia_hibrido = (acertos_hibrido / total_testes_hibrido) * 100\n",
    "\n",
    "print(f\"\\n--- Performance Final dos Modelos ---\")\n",
    "print(f\"Acurácia do Baseline (Rota Mais Frequente): {acuracia_baseline:.2f}%\")\n",
    "print(f\"Acurácia do SVD: 17.39%\")\n",
    "print(f\"Acurácia do Cadeias de Markov: {acuracia_markov:.2f}%\")\n",
    "print(f\"Acurácia do Modelo Híbrido: {acuracia_hibrido:.2f}%\")\n",
    "\n",
    "if acuracia_hibrido > acuracia_baseline:\n",
    "    print(\"\\nAVALIAÇÃO: SUCESSO! O modelo Híbrido superou o baseline e é o nosso melhor modelo!\")\n",
    "else:\n",
    "    print(\"\\nAVALIAÇÃO: O modelo Híbrido não superou o baseline. O comportamento de lealdade à rota ainda é a melhor estratégia.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "654f2009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados divididos por tempo.\n",
      "Data de corte: 2024-02-01\n",
      "Período de Treino: 2021-01-01 a 2024-02-01\n",
      "Período de Teste: 2024-02-01 a 2024-04-01\n",
      "Dados de treino: 261866 interações\n",
      "Dados de teste: 25269 interações\n"
     ]
    }
   ],
   "source": [
    "# --- MUDANÇA NA ETAPA 2: Divisão Temporal ---\n",
    "\n",
    "# Encontra a data mais recente no nosso dataframe de recomendação\n",
    "data_mais_recente = df_recomendacao['datetime'].max()\n",
    "# Define a data de corte (ex: 30 dias antes da data mais recente)\n",
    "data_corte = data_mais_recente - pd.Timedelta(days=60)\n",
    "\n",
    "# O conjunto de treino são todos os dados ANTES da data de corte\n",
    "train_data = df_recomendacao[df_recomendacao['datetime'] < data_corte]\n",
    "# O conjunto de teste são todos os dados DEPOIS da data de corte\n",
    "test_data = df_recomendacao[df_recomendacao['datetime'] >= data_corte].copy()\n",
    "\n",
    "print(f\"Dados divididos por tempo.\")\n",
    "print(f\"Data de corte: {data_corte.date()}\")\n",
    "print(f\"Período de Treino: {train_data['datetime'].min().date()} a {train_data['datetime'].max().date()}\")\n",
    "print(f\"Período de Teste: {test_data['datetime'].min().date()} a {test_data['datetime'].max().date()}\")\n",
    "print(f\"Dados de treino: {len(train_data)} interações\")\n",
    "print(f\"Dados de teste: {len(test_data)} interações\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be10cfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a reavaliação do modelo Baseline com a divisão temporal...\n",
      "\n",
      "--- Performance do Modelo (Avali-ação Temporal) ---\n",
      "Acurácia@1 (Acertar a 1ª recomendação): 23.82%\n",
      "Recall@5 (Acertar entre as 5 primeiras): 47.47%\n",
      "\n",
      "\n",
      "--- Simulação de Impacto no Negócio (Backtesting) ---\n",
      "Clientes únicos no período de teste: 12809\n",
      "O modelo gerou uma recomendação correta (dentro do Top 5) para 5744 desses clientes.\n",
      "Taxa de Acerto do Modelo por Cliente: 44.84%\n",
      "\n",
      "--- Conclusão da Prova de Valor ---\n",
      "O backtesting valida que o modelo de recomendação baseado em histórico é eficaz.\n",
      "A métrica de Recall@5 de 47.47% indica que, para quase metade das futuras compras, a rota correta estaria entre as 5 sugestões apresentadas.\n",
      "Se esta estratégia fosse aplicada aos 50.000 clientes-alvo, poderíamos esperar que aproximadamente 23732 deles recebessem a recomendação correta em sua próxima compra, aumentando a probabilidade de conversão.\n"
     ]
    }
   ],
   "source": [
    "# ETAPA 3: Reavaliação do Baseline e Prova de Valor com Backtesting\n",
    "\n",
    "print(\"Iniciando a reavaliação do modelo Baseline com a divisão temporal...\")\n",
    "\n",
    "# --- Parte 1: Treinar o modelo Baseline com os novos dados de treino ---\n",
    "# O modelo agora aprende apenas com o histórico ANTES da data de corte\n",
    "top_5_frequent_routes = train_data.groupby('fk_contact')['rota'].apply(lambda x: x.value_counts().head(5).index.tolist())\n",
    "baseline_model_top5 = top_5_frequent_routes.to_dict()\n",
    "\n",
    "# Mapeia as 5 principais recomendações para cada cliente no conjunto de teste\n",
    "test_data.loc[:, 'recomendacao_top5'] = test_data['fk_contact'].map(baseline_model_top5)\n",
    "# Garante que a coluna seja uma lista vazia para clientes sem histórico no treino, evitando erros\n",
    "test_data.loc[:, 'recomendacao_top5'] = test_data['recomendacao_top5'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "# A recomendação principal (Top 1) é o primeiro item da lista\n",
    "test_data.loc[:, 'recomendacao_top1'] = test_data['recomendacao_top5'].apply(lambda x: x[0] if x else None)\n",
    "\n",
    "# --- Parte 2: Calcular as métricas de performance no conjunto de teste ---\n",
    "\n",
    "# Acurácia@1: Verifica se a principal recomendação foi a rota comprada\n",
    "acertos_top1 = (test_data['recomendacao_top1'] == test_data['proxima_rota']).sum()\n",
    "acuracia_at_1 = (acertos_top1 / len(test_data)) * 100\n",
    "\n",
    "# Recall@5: Verifica se a rota comprada estava entre as 5 recomendações\n",
    "def check_hit_top5(row):\n",
    "    return row['proxima_rota'] in row['recomendacao_top5']\n",
    "\n",
    "hits_top5 = test_data.apply(check_hit_top5, axis=1).sum()\n",
    "recall_at_5 = (hits_top5 / len(test_data)) * 100\n",
    "\n",
    "print(f\"\\n--- Performance do Modelo (Avali-ação Temporal) ---\")\n",
    "print(f\"Acurácia@1 (Acertar a 1ª recomendação): {acuracia_at_1:.2f}%\")\n",
    "print(f\"Recall@5 (Acertar entre as 5 primeiras): {recall_at_5:.2f}%\")\n",
    "\n",
    "# --- Parte 3: Simulação de Impacto no Negócio (Prova de Valor) ---\n",
    "# Aqui, medimos a \"taxa de acerto\" do modelo no universo de clientes do teste\n",
    "\n",
    "clientes_unicos_no_teste = test_data['fk_contact'].nunique()\n",
    "\n",
    "# Filtra o dataframe para incluir apenas as previsões corretas (hits)\n",
    "acertos_df = test_data[test_data.apply(check_hit_top5, axis=1)]\n",
    "clientes_impactados_pelo_modelo = acertos_df['fk_contact'].nunique()\n",
    "\n",
    "taxa_de_acerto_clientes = (clientes_impactados_pelo_modelo / clientes_unicos_no_teste) * 100\n",
    "vendas_adicionais_estimadas = (50000 * (recall_at_5 / 100))\n",
    "\n",
    "print(f\"\\n\\n--- Simulação de Impacto no Negócio (Backtesting) ---\")\n",
    "print(f\"Clientes únicos no período de teste: {clientes_unicos_no_teste}\")\n",
    "print(f\"O modelo gerou uma recomendação correta (dentro do Top 5) para {clientes_impactados_pelo_modelo} desses clientes.\")\n",
    "print(f\"Taxa de Acerto do Modelo por Cliente: {taxa_de_acerto_clientes:.2f}%\")\n",
    "\n",
    "print(f\"\\n--- Conclusão da Prova de Valor ---\")\n",
    "print(\"O backtesting valida que o modelo de recomendação baseado em histórico é eficaz.\")\n",
    "print(f\"A métrica de Recall@5 de {recall_at_5:.2f}% indica que, para quase metade das futuras compras, a rota correta estaria entre as 5 sugestões apresentadas.\")\n",
    "print(f\"Se esta estratégia fosse aplicada aos 50.000 clientes-alvo, poderíamos esperar que aproximadamente {int(vendas_adicionais_estimadas)} deles recebessem a recomendação correta em sua próxima compra, aumentando a probabilidade de conversão.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24e0c698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a geração dos artefatos finais...\n",
      "Treinando o modelo final com os dados históricos de recompra...\n",
      "Modelo final treinado.\n",
      "Calculando as rotas de fallback (mais populares no geral)...\n",
      "As rotas de fallback são: ['Rodoviária 1 -> Rodoviária 17', 'Rodoviária 3 -> Rodoviária 18', 'Rodoviária 1 -> Rodoviária 33', 'Rodoviária 6 -> Rodoviária 18', 'Rodoviária 1 -> Rodoviária 9']\n",
      "Lista de fallback salva com sucesso em: C:\\Users\\pedro\\Documents\\Estudos\\FIAP\\Challenges\\ClickBus\\Desafios\\desafio2\\api\\modelos\\fallback_routes.json\n",
      "\n",
      "Gerando arquivo de recomendações para TODOS os clientes (para a API)...\n",
      "Arquivo 'recomendacoes_completas_api.csv' com 375590 clientes salvo com sucesso.\n",
      "\n",
      "Gerando arquivo final do entregável com os Top 50k clientes...\n",
      "Arquivo do entregável 'recomendacoes_finais_desafio3.csv' com 50000 clientes salvo com sucesso.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fk_contact</th>\n",
       "      <th>probabilidade_recompra_30d</th>\n",
       "      <th>previsao_dias_prox_compra</th>\n",
       "      <th>recomendacoes_rotas_top5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cliente 100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[Rodoviária 1 -&gt; Rodoviária 55, Rodoviária 451...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cliente 100029</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[Rodoviária 1 -&gt; Rodoviária 17, Rodoviária 3 -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cliente 100056</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[Rodoviária 1 -&gt; Rodoviária 17, Rodoviária 3 -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cliente 100078</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[Rodoviária 64 -&gt; Rodoviária 18, Rodoviária 1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cliente 100082</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>[Rodoviária 140 -&gt; Rodoviária 17, Rodoviária 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fk_contact  probabilidade_recompra_30d  previsao_dias_prox_compra  \\\n",
       "0     Cliente 100                       100.0                        0.9   \n",
       "1  Cliente 100029                       100.0                        0.2   \n",
       "2  Cliente 100056                       100.0                        0.4   \n",
       "3  Cliente 100078                       100.0                        0.1   \n",
       "4  Cliente 100082                       100.0                        1.6   \n",
       "\n",
       "                            recomendacoes_rotas_top5  \n",
       "0  [Rodoviária 1 -> Rodoviária 55, Rodoviária 451...  \n",
       "1  [Rodoviária 1 -> Rodoviária 17, Rodoviária 3 -...  \n",
       "2  [Rodoviária 1 -> Rodoviária 17, Rodoviária 3 -...  \n",
       "3  [Rodoviária 64 -> Rodoviária 18, Rodoviária 1 ...  \n",
       "4  [Rodoviária 140 -> Rodoviária 17, Rodoviária 3...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Iniciando a geração dos artefatos finais...\")\n",
    "\n",
    "# --- Passo 1: Carregar dados e treinar o modelo final ---\n",
    "load_dotenv(find_dotenv())\n",
    "CSV_PATH = os.getenv(\"CSV_PATH\")\n",
    "# df_recomendacao já foi criado nas células anteriores e é usado para treinar o modelo\n",
    "df_recomendacao = df_recomendacao.sort_values(by=['fk_contact', 'datetime'])\n",
    "\n",
    "print(\"Treinando o modelo final com os dados históricos de recompra...\")\n",
    "top_5_frequent_routes_final = df_recomendacao.groupby('fk_contact')['rota'].apply(lambda x: x.value_counts().head(5).index.tolist())\n",
    "modelo_final = top_5_frequent_routes_final.to_dict()\n",
    "print(\"Modelo final treinado.\")\n",
    "\n",
    "# --- Passo 2: Calcular as rotas de fallback ---\n",
    "print(\"Calculando as rotas de fallback (mais populares no geral)...\")\n",
    "top_5_rotas_globais = df_recomendacao['rota'].value_counts().head(5).index.tolist()\n",
    "print(f\"As rotas de fallback são: {top_5_rotas_globais}\")\n",
    "\n",
    "# Salva o fallback para a API\n",
    "caminho_base_api = os.path.abspath(os.path.join(os.getenv(\"CSV_PATH\"), '..', '..', 'desafio2', 'api', 'modelos'))\n",
    "os.makedirs(caminho_base_api, exist_ok=True)\n",
    "caminho_fallback = os.path.join(caminho_base_api, 'fallback_routes.json')\n",
    "with open(caminho_fallback, 'w') as f:\n",
    "    json.dump(top_5_rotas_globais, f)\n",
    "print(f\"Lista de fallback salva com sucesso em: {caminho_fallback}\")\n",
    "\n",
    "# --- Passo 3: Gerar o arquivo COMPLETO para a API ---\n",
    "print(\"\\nGerando arquivo de recomendações para TODOS os clientes (para a API)...\")\n",
    "caminho_vendas_completo = f'{CSV_PATH}vendas.csv'\n",
    "df_vendas_completo = pd.read_csv(caminho_vendas_completo, sep=',', encoding='utf-8')\n",
    "todos_clientes_unicos = df_vendas_completo['fk_contact'].unique()\n",
    "\n",
    "# Gera recomendações para todos, usando o fallback para quem não tem histórico de recompra\n",
    "recomendacoes_completas = {cliente: modelo_final.get(cliente, top_5_rotas_globais) for cliente in todos_clientes_unicos}\n",
    "\n",
    "df_recomendacoes_api = pd.DataFrame(list(recomendacoes_completas.items()), columns=['fk_contact', 'recomendacoes_rotas_top5'])\n",
    "\n",
    "# Salva o arquivo para a API\n",
    "caminho_api_csv = os.path.join(CSV_PATH, 'recomendacoes_completas_api.csv')\n",
    "df_recomendacoes_api.to_csv(caminho_api_csv, index=False)\n",
    "print(f\"Arquivo '{os.path.basename(caminho_api_csv)}' com {len(df_recomendacoes_api)} clientes salvo com sucesso.\")\n",
    "\n",
    "# --- Passo 4: Gerar o arquivo do ENTREGÁVEL com os Top 50k ---\n",
    "print(\"\\nGerando arquivo final do entregável com os Top 50k clientes...\")\n",
    "caminho_previsoes = f'{CSV_PATH}previsoes_finais_desafio2.csv'\n",
    "df_previsoes = pd.read_csv(caminho_previsoes)\n",
    "clientes_alvo_50k = df_previsoes.nlargest(50000, 'probabilidade_recompra_30d')\n",
    "\n",
    "# Faz o merge dos 50k clientes com a base de recomendações COMPLETA\n",
    "df_entregavel_50k = pd.merge(clientes_alvo_50k, df_recomendacoes_api, on='fk_contact', how='left')\n",
    "\n",
    "# Garante que não haja nulos caso algum cliente dos 50k não estivesse no arquivo de vendas por algum motivo\n",
    "df_entregavel_50k['recomendacoes_rotas_top5'] = df_entregavel_50k['recomendacoes_rotas_top5'].apply(lambda x: x if isinstance(x, list) else top_5_rotas_globais)\n",
    "\n",
    "caminho_entregavel_csv = os.path.join(CSV_PATH, 'recomendacoes_finais_desafio3.csv')\n",
    "df_entregavel_50k.to_csv(caminho_entregavel_csv, index=False)\n",
    "print(f\"Arquivo do entregável '{os.path.basename(caminho_entregavel_csv)}' com {len(df_entregavel_50k)} clientes salvo com sucesso.\")\n",
    "\n",
    "df_entregavel_50k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248ec1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
